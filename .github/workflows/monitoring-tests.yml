name: Kubernetes Monitoring Tests

on:
  push:
    branches: [ main ]
    paths:
      - 'demo-app/monitoring-demo/**'
      - '.github/workflows/monitoring-tests.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'demo-app/monitoring-demo/**'
      - '.github/workflows/monitoring-tests.yml'
  workflow_dispatch:  # Allow manual triggering

jobs:
  test-kind-deployment:
    name: Test Kind Deployment
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: 'latest'

      - name: Setup KinD cluster
        uses: helm/kind-action@v1.8.0
        with:
          cluster_name: kind-monitoring-test
          config: kind-lab/kind-config.yaml
          wait: 120s

      - name: Show cluster info
        run: |
          kubectl cluster-info
          kubectl get nodes
          kubectl version

      - name: Deploy monitoring stack
        working-directory: demo-app/monitoring-demo
        run: |
          chmod +x ./deploy-monitoring.sh
          ./deploy-monitoring.sh kind kind-monitoring-test
          
      - name: Wait for deployments to be ready
        run: |
          echo "Waiting for Prometheus Operator deployment..."
          kubectl -n monitoring wait --for=condition=available deployment/prometheus-kube-prometheus-operator --timeout=180s || true
          
          echo "Waiting for Prometheus deployment..."
          kubectl -n monitoring wait --for=condition=ready pod -l app.kubernetes.io/name=prometheus --timeout=180s || true
          
          echo "Waiting for Grafana deployment..."
          kubectl -n monitoring wait --for=condition=available deployment/prometheus-grafana --timeout=180s || true
      
      - name: Apply ServiceMonitors with correct labels
        working-directory: demo-app/monitoring-demo
        run: |
          echo "Getting Prometheus release label..."
          HELM_RELEASE_LABEL=$(kubectl get prometheus -n monitoring -o jsonpath='{.items[0].spec.serviceMonitorSelector.matchLabels.release}' 2>/dev/null || echo "prometheus")
          echo "Helm release label: $HELM_RELEASE_LABEL"
          
          # Update and apply standard ServiceMonitors with correct label
          sed -i "s/release: prometheus/release: $HELM_RELEASE_LABEL/g" service-monitors.yaml
          kubectl apply -f service-monitors.yaml
          
          # Apply CI-specific ServiceMonitors that use app.kubernetes.io/name label
          kubectl apply -f ci-service-monitors.yaml
          
          echo "Checking that ServiceMonitors were created:"
          kubectl get servicemonitor -A || echo "No ServiceMonitors found"

      - name: Configure direct scrape fallback
        working-directory: demo-app/monitoring-demo
        run: |
          # Run the CI script to add direct scrape configurations
          chmod +x ci-add-direct-scrape.sh
          ./ci-add-direct-scrape.sh
          
          echo "Giving extra time for service discovery..."
          sleep 90
          
          # Check if targets are being discovered
          echo "Verifying Prometheus targets after configuration..."
          PROM_POD=$(kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus -o jsonpath='{.items[0].metadata.name}')
          kubectl port-forward pod/$PROM_POD 9090:9090 -n monitoring &
          PF_PID=$!
          sleep 5
          
          # Check targets
          echo "Checking for active targets:"
          curl -s http://localhost:9090/api/v1/targets | grep -o '"state":"active"' | wc -l
          
          # Kill port-forward
          kill $PF_PID || true
      
      - name: List all resources in monitoring namespace
        run: |
          kubectl get all -n monitoring

      - name: Run automated tests using test-monitoring.sh script
        working-directory: demo-app/monitoring-demo
        env:
          CI: "true"
        run: |
          chmod +x ./test-monitoring.sh
          
          echo "Checking Prometheus targets directly before running tests..."
          PROM_POD=$(kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus -o jsonpath='{.items[0].metadata.name}')
          echo "Prometheus pod: $PROM_POD"
          
          # Forward port to access Prometheus
          kubectl port-forward pod/$PROM_POD 9090:9090 -n monitoring &
          PF_PID=$!
          sleep 5
          
          # Check targets
          echo "Current Prometheus targets:"
          curl -s http://localhost:9090/api/v1/targets | grep -o '"scrapePool":"[^"]*"' | sort | uniq
          echo "Target states:"
          curl -s http://localhost:9090/api/v1/targets | grep -o '"state":"[^"]*"' | sort | uniq -c
          
          # Kill port-forward
          kill $PF_PID || true
          
          echo "Checking Prometheus configuration:"
          kubectl -n monitoring get secret -l app.kubernetes.io/name=prometheus -o name | xargs -I{} kubectl -n monitoring get {} -o jsonpath='{.data.prometheus\.yaml}' | base64 -d | grep -A 3 "scrape_configs:" || echo "Could not retrieve Prometheus config"
          
          echo "ServiceMonitors in the cluster:"
          kubectl get servicemonitor -A
          
          echo "Running tests with CI=true to be more lenient with timing issues..."
          CI=true ./test-monitoring.sh kind kind-monitoring-test
          
      - name: Test monitoring dashboard scripts
        working-directory: demo-app/monitoring-demo
        run: |
          # Test start monitoring script
          chmod +x ./start-monitoring.sh
          if ./start-monitoring.sh | grep -q "Usage"; then
            echo "✅ start-monitoring.sh script executed successfully"
          else
            echo "❌ start-monitoring.sh script failed to execute properly"
            exit 1
          fi
          
          # Test dashboard import (using kubectl port-forward)
          echo "Testing dashboard import..."
          kubectl port-forward svc/prometheus-grafana 3000:80 -n monitoring &
          PORT_FWD_PID=$!
          sleep 5
          
          IMPORT_RESULT=$(curl -s -u admin:admin -H "Content-Type: application/json" -X POST -d @test-dashboard.json http://localhost:3000/api/dashboards/db)
          if echo "$IMPORT_RESULT" | grep -q "success"; then
            echo "✅ Test dashboard imported successfully"
          else
            echo "⚠️ Could not import dashboard: $(echo $IMPORT_RESULT | grep -o '"message":"[^"]*"' || echo "Unknown error")"
          fi
          
          # Clean up port forwarding
          kill $PORT_FWD_PID || true

      - name: Clean up
        if: always()
        run: |
          kubectl delete namespace monitoring || true
